{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using_Multi-head-Attention_to_classify_MNIST_images_128_256_512.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2QcmyokWOIHo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Input, layers, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, Softmax, Embedding, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import tensorflow as tf\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "Y_train = to_categorical(Y_train)\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "#tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_vocabs = 256\n",
        "class DotProduct(layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "  def call(self, t_queries, t_keys, t_values):\n",
        "    softmax_layer = Softmax(axis = -1)\n",
        "    softmax_output = softmax_layer(tf.matmul(t_queries, tf.transpose(t_keys, [0, 2, 1]))/np.sqrt(t_queries.shape[2]))\n",
        "    return tf.matmul(softmax_output, t_values)"
      ],
      "metadata": {
        "id": "LUqy8JEbQV6-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(layers.Layer):\n",
        "  def __init__(self, qk_hidden,  v_hidden, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.dense_queries = Dense(qk_hidden)\n",
        "    self.dense_keys = Dense(qk_hidden)\n",
        "    self.dense_values = Dense(v_hidden)\n",
        "    self.dot_product = DotProduct()\n",
        "    self.flatten = Flatten()\n",
        "  def call(self, embedding):\n",
        "    t_queries = self.dense_queries(embedding)\n",
        "    t_keys = self.dense_keys(embedding)\n",
        "    t_values = self.dense_values(embedding)\n",
        "    values_probability = self.dot_product(t_queries, t_keys, t_values)\n",
        "    return values_probability\n",
        "class MultiAttention(layers.Layer):\n",
        "  def __init__(self, qk_hiddens, v_hidden, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.qk_hiddens = qk_hiddens\n",
        "    self.v_hidden = v_hidden\n",
        "    self.list_attention = [Attention(self.qk_hiddens[i], self.v_hidden) for i in range(len(self.qk_hiddens))]\n",
        "    self.concatenate = Concatenate(axis = 2)\n",
        "  def call(self, embedding):\n",
        "    mutil_attention = [attention(embedding) for attention in self.list_attention]\n",
        "    return self.concatenate(mutil_attention)"
      ],
      "metadata": {
        "id": "KXzh8XFn-wAv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input((X_train.shape[1]))\n",
        "n_embedding = 128\n",
        "embedding = Embedding(n_vocabs, n_embedding, input_length = X_train.shape[1])(input)\n",
        "multi_attention = MultiAttention([128, 256, 512], 256)(embedding)\n",
        "flatten = Flatten()(multi_attention)\n",
        "dense = Dense(128, activation = \"relu\")(flatten)\n",
        "output = Dense(10, activation = \"softmax\")(dense)\n",
        "model_attention = Model(input, output)\n",
        "model_attention.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
        "with tf.device(\"/gpu:0\"):\n",
        "  model_attention.fit(X_train, Y_train, batch_size = 32, epochs = 10, verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyczMMG0VyUg",
        "outputId": "58e3528c-1200-4446-be1f-04f34ed02908"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 513s 273ms/step - loss: 0.5141 - acc: 0.8371\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 511s 272ms/step - loss: 0.2068 - acc: 0.9391\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 509s 271ms/step - loss: 0.1814 - acc: 0.9465\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.1633 - acc: 0.9524\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.1401 - acc: 0.9588\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.1240 - acc: 0.9632\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.1030 - acc: 0.9687\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.0992 - acc: 0.9708\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.0815 - acc: 0.9753\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 512s 273ms/step - loss: 0.0813 - acc: 0.9762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Nếu k dùng attention layer phía trước mà dùng các pixels ảnh làm feature luôn.\n",
        "input = Input((X_train.shape[1]))\n",
        "dense1 = Dense(128, activation = \"relu\")(input)\n",
        "output = Dense(10, activation = \"softmax\")(dense1)\n",
        "model_mlp = Model(input, output)\n",
        "model_mlp.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"acc\"])\n",
        "with tf.device(\"/gpu:0\"):\n",
        "  model_mlp.fit(X_train, Y_train, batch_size = 32, epochs = 10, verbose = 1)\n",
        "#Hiệu năng thấp hơn là training với Attention Layer"
      ],
      "metadata": {
        "id": "DO0Qc54CJxni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7959024b-e0a0-4d9b-cc63-55ef3b679613"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.5813 - acc: 0.8565\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3607 - acc: 0.9116\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2734 - acc: 0.9297\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2364 - acc: 0.9401\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2186 - acc: 0.9445\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2097 - acc: 0.9479\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1903 - acc: 0.9524\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1850 - acc: 0.9531\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1851 - acc: 0.9561\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1747 - acc: 0.9563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_test, Y_test) = mnist.load_data()[1]\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "model_attention.evaluate(X_test, Y_test)\n",
        "model_mlp.evaluate(X_test, Y_test)\n",
        "#Dùng thêm Attention Layer có hiệu năng tốt hơn trên tập test\n",
        "#Tuy nhiên thời gian training dùng thêm attention layer rất lâu ! dù đã có GPU của colab"
      ],
      "metadata": {
        "id": "VggapgHylxX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4b6dac-5661-47b7-a44e-1627de6338fc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 27s 83ms/step - loss: 0.2222 - acc: 0.9596\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2867 - acc: 0.9477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2867424190044403, 0.947700023651123]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}